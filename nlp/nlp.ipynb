{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033093ec-279b-4022-81b9-7d0b33c1c318",
   "metadata": {},
   "source": [
    "## Natural Language Processing with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb90c09b-7916-48f7-9482-f0852c6931b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the helper function\n",
    "#!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56da8d85-11fc-4552-ab3c-94e58d129b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import series of helper functions for the notebook\n",
    "#from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c65bd-3245-46d4-ad45-efc5b22b25e8",
   "metadata": {},
   "source": [
    "### Download a text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6d8987-9dc7-4b22-8dc0-812ff30b98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data (same as from Kaggle)\n",
    "#!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f0fc29-c3d6-4a4c-a3fa-1b6561fc9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unzip the dwnloaded file\n",
    "# import zipfile\n",
    "\n",
    "# zip_ref = zipfile.ZipFile((\"nlp_getting_started.zip\"))\n",
    "# zip_ref.extractall()\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d063f9-71d0-45b4-be35-1f9de79fa780",
   "metadata": {},
   "source": [
    "### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1a5bdf-4382-484e-94f3-5af439505443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1171d661-afca-4149-a950-873d0bc50da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2c0f6e-0abe-48f9-bb82-f808b6b77a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e400716e-56b2-480f-a0a5-893585ec0d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89cd51a-6a5b-4944-ad31-9c4d6fe19c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id          7613\n",
       " keyword     7552\n",
       " location    5080\n",
       " text        7613\n",
       " target      7613\n",
       " dtype: int64,\n",
       " id          3263\n",
       " keyword     3237\n",
       " location    2158\n",
       " text        3263\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b26424e6-4aea-443a-8208-87a563f76b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c311ceb0-10b8-489f-a327-fa1ea103a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled[\"target\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8335136a-7ff8-4fee-961c-b940efb58f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f409888d-5790-4461-acc5-f4c8c9868c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'keyword', 'location', 'text', 'target'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a82368-bea7-4fd3-8ef4-3ad7e6318ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 [not disaster]\n",
      "Test: I crashed my car into a parked car the other day... #modestmouseremix #truestory\n",
      "-----\n",
      "\n",
      "Target: 0 [not disaster]\n",
      "Test: @harveymaine AAAA ok lemme move to another roomr so no one hears my gay ass screams\n",
      "-----\n",
      "\n",
      "Target: 1 [disaster]\n",
      "Test: 'There was a small earthquake in LA but don't worry Emily Rossum is fine' #difficultpeople is great\n",
      "-----\n",
      "\n",
      "Target: 1 [disaster]\n",
      "Test: APC Chieftain Tasks Dickson On N15b Floods Donation To Bayelsa http://t.co/LqGOe7psXp\n",
      "-----\n",
      "\n",
      "Target: 1 [disaster]\n",
      "Test: @JasonPope2 @JohnFugelsang again I didn't say it was. I was referring to the main 2 buildings. 7 was hit by rubble\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualize the random samples\n",
    "for row in train_df[[\"text\", \"target\"]].sample(n=5).itertuples():\n",
    "    _, text_value, target_value = row\n",
    "    print(f\"Target: {target_value}\", \"[disaster]\" if int(target_value) > 0 else \"[not disaster]\")\n",
    "    print(f\"Test: {text_value}\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "055bf704-058b-4bcd-ae22-bc946b2f9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spliting the data into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                           train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                           test_size=0.1,\n",
    "                                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd40dbb-d4b5-4fe2-8782-c2b27f3eb98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5061af8-591a-43cc-8df8-882e743d8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the 5 training sentences and their labels\n",
    "train_sentences[:5], train_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac72819-8b27-45ea-8857-771fd05cfb67",
   "metadata": {},
   "source": [
    "### Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffa1d0-969a-44be-82d9-0ad956041ab7",
   "metadata": {},
   "source": [
    "#### Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31a85d7-7f07-43e6-9891-78044de2aa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 20:26:26.543244: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-01-29 20:26:26.543278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: bourne\n",
      "2022-01-29 20:26:26.543289: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: bourne\n",
      "2022-01-29 20:26:26.543357: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 495.29.5\n",
      "2022-01-29 20:26:26.543414: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 495.29.5\n",
      "2022-01-29 20:26:26.543425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 495.29.5\n",
      "2022-01-29 20:26:26.543668: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "default_text_vectorization = TextVectorization(max_tokens=None,\n",
    "                                               standardize=\"lower_and_strip_punctuation\", \n",
    "                                               split=\"whitespace\",\n",
    "                                               ngrams=None,\n",
    "                                               output_mode=\"int\",\n",
    "                                               output_sequence_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0d385e-27fa-428d-9323-faefd8519b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_words = sum(len(words.split()) for words in train_sentences)\n",
    "print(total_train_words)\n",
    "avg_words_per_sentence = total_train_words / len(train_sentences)\n",
    "round(avg_words_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bef93511-cfa7-4074-b975-879ff678aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "302bfc9e-9c46-4f13-901a-674e2474fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958cafd1-7d26-42a0-882e-9c00246132ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[   1, 1338, 1702,   22,    1,  282,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"covid 19 cases are increasing again !!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd8ab819-575f-40b1-aa26-a4fa4cc26dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Find out how your fund was used for Typhoon Haiyan in the Philippines. See @DevPeace Haiyan Relief Funds Report http://t.co/JwxrX1LsqO      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 653,   36,   62,   33, 2984,   23,  493,   10,  494, 3794,    4,\n",
       "           2, 1186,   99,    1]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "import random\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e0d1202-c27a-4ec6-9f65-dd73e84d1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e746f-d2e2-4879-9c47-52408f839ba8",
   "metadata": {},
   "source": [
    "#### Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f91581e-5516-413f-863f-84299c6f7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "embedding = Embedding(input_dim=len(text_vectorizer.get_vocabulary()),\n",
    "                      output_dim=128,\n",
    "                      embeddings_initializer=\"uniform\",\n",
    "                      input_length=max_length,\n",
    "                      name=\"embedding_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0153eb-f7c6-4422-8770-51b1885828a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "@SnowyWolf5 @TheGreenParty Besides would you rather shut down a whole nuclear reactor for maintenance or a wind turbine at a time?      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.02739256,  0.03522961,  0.0478737 , ..., -0.01285902,\n",
       "          0.04138485, -0.00105117],\n",
       "        [-0.0304304 ,  0.00092275,  0.00728374, ..., -0.00593842,\n",
       "         -0.03516513,  0.00155967],\n",
       "        [-0.02039832, -0.04198135,  0.01101891, ..., -0.03038355,\n",
       "          0.03587143,  0.0358495 ],\n",
       "        ...,\n",
       "        [-0.03508195,  0.01448471,  0.00513798, ...,  0.04485155,\n",
       "          0.03976364, -0.03543619],\n",
       "        [ 0.00846229,  0.00479295,  0.02089298, ...,  0.0283854 ,\n",
       "          0.02527254, -0.01181388],\n",
       "        [-0.04538491,  0.02194316,  0.02299335, ...,  0.03143641,\n",
       "         -0.00354359,  0.04591903]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703887b-293c-452a-8cfd-d9fabd29ff0a",
   "metadata": {},
   "source": [
    "#### More specifically, we'll be building the following:\n",
    "\n",
    "   * Model 0: Naive Bayes (baseline)\n",
    "   * Model 1: Feed-forward neural network (dense model)\n",
    "   * Model 2: LSTM model\n",
    "   * Model 3: GRU model\n",
    "   * Model 4: Bidirectional-LSTM model\n",
    "   * Model 5: 1D Convolutional Neural Network\n",
    "   * Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
    "   * Model 7: Same as model 6 with 10% of training data\n",
    "    \n",
    "##### **Model 0** is the simplest to acquire a **baseline** which we'll expect each other of the other deeper models to beat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790874e-1f8b-4c59-b286-9cd9c0a140e9",
   "metadata": {},
   "source": [
    "### **Model 0: Getting a baseline**\n",
    "\n",
    "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (**term frequency-inverse document frequency**) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the Scikit-Learn machine learning map.\n",
    "\n",
    " This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07eb1d76-8c64-4e56-866e-e22b5e77577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "], verbose=True)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "fitted_steps = model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe326aa4-24db-4298-b903-61ce17d21b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())],\n",
       " 'verbose': True,\n",
       " 'tfidf': TfidfVectorizer(),\n",
       " 'clf': MultinomialNB(),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.float64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None,\n",
       " 'clf__alpha': 1.0,\n",
       " 'clf__class_prior': None,\n",
       " 'clf__fit_prior': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_steps.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f71b0af-3f5e-4c38-b914-b030e7ca496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e25522c4-03ad-4c77-9fc8-cd540ca5c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.26509186351706"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e7aa34e-449c-438e-bbc6-1aa65d46ef76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction from baseline model\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83c4a8-4e6c-4d56-84d0-c0c91b050a50",
   "metadata": {},
   "source": [
    "#### Creating an evaluation function for our model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "416b8d71-8e35-4be8-9ad9-158955c5a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c9126c4-24cb-4eff-99d3-251663029248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels, y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bf4f5-8da0-4b92-85a7-12e6bf5b7c97",
   "metadata": {},
   "source": [
    "### **Model 1: A Dense model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99ca04cb-f838-4d58-825c-18882a1e50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee3d8802-63a8-4663-a7b8-f9b02e2ade3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAvgPool1D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "inputs = Input(shape=(1,), name=\"input_layer\", dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = GlobalAvgPool1D()(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\", name=\"model_1_ouptut\")(x)\n",
    "\n",
    "model_1 = Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9ece41c-8c21-49f4-af20-ae2b612473ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss=binary_crossentropy, \n",
    "                optimizer= Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca086032-9d3b-44e0-884f-bf2f6a0b1bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " model_1_ouptut (Dense)      (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f14e67-3dd5-428b-80b3-7f4f24d9b46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220129-202631\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model_1_history = model_1.fit(train_sentences,\n",
    "                            train_labels,\n",
    "                            epochs=5,\n",
    "                            validation_data=(val_sentences, val_labels),\n",
    "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07b6329e-f5b8-4cab-997a-16ba349c7771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4766846001148224, 0.787401556968689]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "696a88cb-9e8a-4438-a231-3f9c0babb822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40488204],\n",
       "       [0.7443312 ],\n",
       "       [0.99789494],\n",
       "       [0.10889998],\n",
       "       [0.11143532]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ae4f378-d229-426c-82ee-0a5a8cb88727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "print(model_1_pred_probs.shape)\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "402d9aaa-40d5-4d53-966f-638904cdcae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7914920592553047,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.7846966492209201}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858c917-cc1e-43d0-809d-b0a7ff056251",
   "metadata": {},
   "source": [
    "### **Model 2: LSTM**\n",
    "LSTM = Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b09cff63-4cdb-49db-b25b-dd259c0737b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "inputs = Input(shape=(1,), dtype=tf.string, name=\"lstm_inputs\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = LSTM(64, activation=\"tanh\")(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\", name=\"model_2_lstm_output\")(x)\n",
    "\n",
    "model_2 = Model(inputs,outputs, name=\"model_2_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "133677d5-8b48-4128-bc36-a3a0e2e132a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_inputs (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " model_2_lstm_output (Dense)  (None, 1)                65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get the summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e0f13bd-cc61-407a-9941-90d34b697a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_2.compile(loss=binary_crossentropy,\n",
    "                optimizer=Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d449dd1e-086c-465e-b0df-1bf5fdc08fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_lstm/20220129-202646\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 19ms/step - loss: 0.2208 - accuracy: 0.9210 - val_loss: 0.5403 - val_accuracy: 0.7743\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1614 - accuracy: 0.9415 - val_loss: 0.6062 - val_accuracy: 0.7769\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1274 - accuracy: 0.9521 - val_loss: 0.7357 - val_accuracy: 0.7795\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1073 - accuracy: 0.9596 - val_loss: 0.8344 - val_accuracy: 0.7874\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0849 - accuracy: 0.9656 - val_loss: 0.9325 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"model_2_lstm\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b45e84e9-ccde-4216-9bad-5a200f6f3db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.6124668e-03],\n",
       "       [6.8414563e-01],\n",
       "       [9.9959624e-01],\n",
       "       [3.4396797e-02],\n",
       "       [2.2518635e-04]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c66dd3a4-ae11-4777-8fc8-7049bcc89cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out pred probs and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9fbd6520-de6c-4f24-b8f8-dd7cf86d10a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7819506047193071,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7772730329412364}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model 2 results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1468f4-6908-4038-b2ba-d12961c9c9a2",
   "metadata": {},
   "source": [
    "### **Model 3: GRU**\n",
    "GRU = Gated recurrent unit (one of the most popular and useful recurrent layer types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45523a2c-6b17-4720-b924-316853fdbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the RNN model using GRU layer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GRU, Input\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "inputs = Input(shape=(1, ), dtype=tf.string, name=\"model_3_input\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = GRU(64, activation=\"tanh\")(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\", name=\"model_3_output\")(x)\n",
    "\n",
    "model_3 = Model(inputs, outputs, name=\"model_3_gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b7d2fdf-4887-4e3f-b04e-c202a0e45bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_3.compile(loss=binary_crossentropy,\n",
    "                optimizer=Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e56069bc-37b6-4ae5-8fb4-33b9d116ebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_gru\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_3_input (InputLayer)  [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " model_3_output (Dense)      (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "770befc0-de9f-4a57-a792-1555dd4df9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_gru/20220129-202707\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 19ms/step - loss: 0.1560 - accuracy: 0.9385 - val_loss: 0.6572 - val_accuracy: 0.7782\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0861 - accuracy: 0.9686 - val_loss: 0.7952 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0722 - accuracy: 0.9720 - val_loss: 1.0512 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0677 - accuracy: 0.9745 - val_loss: 1.0347 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0556 - accuracy: 0.9766 - val_loss: 1.0512 - val_accuracy: 0.7690\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"model_3_gru\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b5313c6-407b-4d14-90d1-bf2cf93eada1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.2815785e-02],\n",
       "        [7.8835511e-01],\n",
       "        [9.9976885e-01],\n",
       "        [9.5390022e-02],\n",
       "        [1.3333559e-04],\n",
       "        [9.9963820e-01],\n",
       "        [8.2681853e-01],\n",
       "        [9.9993140e-01],\n",
       "        [9.9983907e-01],\n",
       "        [9.4554180e-01]], dtype=float32),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the trained model\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs[:10], model_3_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2edae446-abfc-46bc-bb6f-51e339fcb079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 3 pred probs into labels\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea3698bc-120a-4aae-8715-f47c1df5bf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.9028871391076,\n",
       " 'precision': 0.7689137548517897,\n",
       " 'recall': 0.7690288713910761,\n",
       " 'f1': 0.768063295978387}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results for model 3\n",
    "model_3_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668437a1-71f4-4b4c-a36b-2151296e2964",
   "metadata": {},
   "source": [
    "### **Model 4: Bidirectional RNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2124e26f-3398-4537-9c65-53d74509d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a bidirectional RNN in TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "inputs = Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = Model(inputs, outputs, name=\"model_4_bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49a00188-bdd6-4d50-a984-fe6d66de610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_4 summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04f5a05d-7a5c-440e-8502-9e30f5cbd060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220129-202728\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 22ms/step - loss: 0.1085 - accuracy: 0.9717 - val_loss: 0.9050 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0597 - accuracy: 0.9764 - val_loss: 1.0827 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0494 - accuracy: 0.9774 - val_loss: 1.2966 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0434 - accuracy: 0.9800 - val_loss: 1.3755 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0363 - accuracy: 0.9825 - val_loss: 1.7084 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model\n",
    "history_model_4 = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_4_bidirectional\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a763a849-7727-48e7-9c70-886ab7072ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.32448292e-04],\n",
       "        [7.30594754e-01],\n",
       "        [9.99986708e-01],\n",
       "        [1.21692926e-01],\n",
       "        [6.80609082e-06],\n",
       "        [9.99942541e-01],\n",
       "        [9.90393937e-01],\n",
       "        [9.99995828e-01],\n",
       "        [9.99990940e-01],\n",
       "        [9.99740720e-01]], dtype=float32),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with our bidirectional model\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10], model_4_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c00a61cc-3c5b-48c7-a1bb-476d02c22239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c48161c8-d269-4b6b-80da-fcdde83fd756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.98425196850394,\n",
       " 'precision': 0.7599947657549518,\n",
       " 'recall': 0.7598425196850394,\n",
       " 'f1': 0.7584680708642795}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 4 results\n",
    "model_4_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4de77-b83d-466b-b859-bab559452e7b",
   "metadata": {},
   "source": [
    "### **Model 5: Conv1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e3ac26e-39b4-4fea-b301-a27554463d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1-dimensional CNN to model sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPool1D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "inputs = Input(shape=(1,), dtype=tf.string, name=\"model_5_input\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\", name=\"model_5_output\")(x)\n",
    "\n",
    "model_5 = Model(inputs, outputs, name=\"model_5_conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bef3149b-9961-4f48-a5c9-7ca5f803b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_5_input (InputLayer)  [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " model_5_output (Dense)      (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 5 summary\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2059d716-04d6-473a-9dfe-b00e6a7cefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_conv1d/20220129-202753\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.1377 - accuracy: 0.9585 - val_loss: 0.8317 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0757 - accuracy: 0.9714 - val_loss: 1.0009 - val_accuracy: 0.7664\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0624 - accuracy: 0.9768 - val_loss: 1.0789 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0548 - accuracy: 0.9785 - val_loss: 1.1674 - val_accuracy: 0.7546\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0504 - accuracy: 0.9778 - val_loss: 1.2061 - val_accuracy: 0.7612\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_model_5 = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              batch_size=32,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_5_conv1d\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2ff5dfd-2af7-441e-a857-cb61fb24cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8.3698869e-02],\n",
       "        [6.6586018e-01],\n",
       "        [9.9995434e-01],\n",
       "        [9.6137673e-02],\n",
       "        [2.8227561e-08]], dtype=float32),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with our 1D CNN\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:5], model_5_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b159ab11-acc1-41d7-8e31-98d2a87fddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 5 pred probs to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cd13944-98bc-4efb-952f-a58ca4d0d7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.11548556430446,\n",
       " 'precision': 0.7622953452640989,\n",
       " 'recall': 0.7611548556430446,\n",
       " 'f1': 0.7591215732608759}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results for model 5\n",
    "model_5_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476d3f5-e724-49b6-bbbf-7dd0f2c8aa04",
   "metadata": {},
   "source": [
    "### **Model 6: TensorFlow Hub Pretrained Sentence Encoder**\n",
    "\n",
    "Using TensorFlow Hub's Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ef2483f-4e1b-4746-8195-a6241ca99416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the USE from tensorflow hub\n",
    "# url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed10fc39-46ab-4119-8241-655df33d0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f6cb036-ec43-46bc-9acb-9331c794b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model using Sequential API\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_6 = Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\", name=\"model_6_output\")\n",
    "], name=\"model_6_use\")\n",
    "\n",
    "# Compile\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15badd1e-b1dc-485b-a672-319f4605f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_use\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " model_6_output (Dense)      (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summmary\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10c14f03-62fc-4ba7-aba2-93ef8bb4979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220129-202815\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 8ms/step - loss: 0.5039 - accuracy: 0.7872 - val_loss: 0.4485 - val_accuracy: 0.8031\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.4146 - accuracy: 0.8140 - val_loss: 0.4370 - val_accuracy: 0.8084\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3999 - accuracy: 0.8228 - val_loss: 0.4321 - val_accuracy: 0.8136\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3923 - accuracy: 0.8259 - val_loss: 0.4269 - val_accuracy: 0.8150\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3857 - accuracy: 0.8307 - val_loss: 0.4284 - val_accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of USE pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "578ecbc8-4805-486b-a325-a9f4a3f5969f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16333416],\n",
       "       [0.7379844 ],\n",
       "       [0.9887543 ],\n",
       "       [0.21095747],\n",
       "       [0.7271445 ],\n",
       "       [0.66852057],\n",
       "       [0.97907925],\n",
       "       [0.97519076],\n",
       "       [0.9222555 ],\n",
       "       [0.0947502 ]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub Model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe24e1b8-2720-417b-8071-9e00175445dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22ca6e05-e121-4131-aa73-0f6d5dc7f698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.8190827553840537,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8146067773916925}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf14166-77fd-4bbd-8452-f8178d22bb60",
   "metadata": {},
   "source": [
    "### **Model 7: TF Hub Pretrained USE but with 10% of training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7801e64b-46ca-4c39-a72f-be52eaa8f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset split \n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae8307bb-2c28-486d-9390-6078b728d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model using Sequential API\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_7 = Sequential([\n",
    "  sentence_encoder_layer,\n",
    "  Dense(64, activation=\"relu\"),\n",
    "  Dense(1, activation=\"sigmoid\", name=\"output_layer\")                               \n",
    "], name=\"model_7_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary (will be same as model_6)\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9034f811-e43e-44b9-8d88-16acb90a6fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20220129-202825\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6714 - accuracy: 0.6818 - val_loss: 0.6490 - val_accuracy: 0.7126\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6007 - accuracy: 0.8088 - val_loss: 0.5911 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.5228 - accuracy: 0.8234 - val_loss: 0.5330 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.4600 - accuracy: 0.8234 - val_loss: 0.5013 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.8394 - val_loss: 0.4857 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the 10% training data subsets\n",
    "model_7_history = model_7.fit(train_sentences_10_percent,\n",
    "                              train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad3b9809-b797-4b6d-a085-ae16f3689cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1814042 ],\n",
       "       [0.5688577 ],\n",
       "       [0.9215586 ],\n",
       "       [0.36991227],\n",
       "       [0.5568163 ],\n",
       "       [0.6910775 ],\n",
       "       [0.8953402 ],\n",
       "       [0.8298417 ],\n",
       "       [0.85683227],\n",
       "       [0.1506845 ]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model trained on 10% of the data\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0124af4-8192-41aa-9350-8beef8539bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn pred probs into labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec0689ee-4b3c-45b8-8527-0461bac4eba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7802422774076316,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7781078501550943}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalaute model 7 predictions\n",
    "model_7_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4ea7c-cc41-4339-90c4-3b7a309da4d9",
   "metadata": {},
   "source": [
    "### **Comparing the peformance of each of our models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "291f2367-a99c-4206-bde6-b5494e4aeed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>78.740157</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>0.781951</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.777273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>76.902887</td>\n",
       "      <td>0.768914</td>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.768063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>75.984252</td>\n",
       "      <td>0.759995</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.758468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>76.115486</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.759122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>81.627297</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.814607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>0.780242</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.778108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  accuracy  precision    recall        f1\n",
       "0_baseline                       79.265092   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   78.740157   0.791492  0.787402  0.784697\n",
       "2_lstm                           77.952756   0.781951  0.779528  0.777273\n",
       "3_gru                            76.902887   0.768914  0.769029  0.768063\n",
       "4_bidirectional                  75.984252   0.759995  0.759843  0.758468\n",
       "5_conv1d                         76.115486   0.762295  0.761155  0.759122\n",
       "6_tf_hub_use_encoder             81.627297   0.819083  0.816273  0.814607\n",
       "7_tf_hub_use_encoder_10_percent  77.952756   0.780242  0.779528  0.778108"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
    "                                  \"1_simple_dense\": model_1_results,\n",
    "                                  \"2_lstm\": model_2_results,\n",
    "                                  \"3_gru\": model_3_results,\n",
    "                                  \"4_bidirectional\": model_4_results,\n",
    "                                  \"5_conv1d\": model_5_results,\n",
    "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac6f6a51-ce52-41cd-a533-f2dac5563065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to the same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
    "# all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2cb3f042-383b-43e5-8c51-1ad798ba82cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86ce0719-a8c9-4b84-8b56-e168d8d2719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c8c9b-d184-4b34-bb0f-18a7b3c6a4f9",
   "metadata": {},
   "source": [
    "### **Saving and loading a trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "26db9b9d-bd67-4363-9d89-1d61652f421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.save(\"saved_models/h5/model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c839e5dc-e648-49e1-a30d-ae97ba93fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required HDF5 format)\n",
    "import tensorflow_hub as hub\n",
    "loaded_model_6 = tf.keras.models.load_model(\"saved_models/h5/model_6.h5\",\n",
    "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8cfd8698-866f-4b49-b1c9-8894c5978904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 21ms/step - loss: 0.4284 - accuracy: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42841193079948425, 0.8162729740142822]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7491997f-9859-4fa0-9ce0-ee2c8238260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/tf/model_6_SavedModel_format/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/tf/model_6_SavedModel_format/assets\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Ecnoder model to SavedModel format (default)\n",
    "model_6.save(\"saved_models/tf/model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9af87a3-a78a-4ae7-8b51-aa4026d4f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a model from the SavedModel format\n",
    "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"saved_models/tf/model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "40ba5710-6ac3-4bb4-b46b-80fcae736f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 51ms/step - loss: 0.4284 - accuracy: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42841193079948425, 0.8162729740142822]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model in SavedModel format\n",
    "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0a2a0-65d7-4356-bed5-d4ae27c77a5f",
   "metadata": {},
   "source": [
    "### **Finding the most wrong examples**\n",
    "\n",
    "Using **Model 6** to create DataFrame with validation sentences, validation labels and best performing model prediction labels + probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3ac7d62-4ac2-44c7-9a8f-5446a6f9d783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.163334\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.737984\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988754\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.210957\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.727144"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                       \"target\": val_labels,\n",
    "                       \"pred\": model_6_preds,\n",
    "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "830de984-5897-4f8c-8949-e58d4e8a0a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04016980-098f-4beb-99a3-f913d1f7533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.821227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>The Sound of Arson</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.769984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   \n",
       "144                                 The Sound of Arson       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.914415  \n",
       "628   0.856423  \n",
       "759   0.854090  \n",
       "49    0.844770  \n",
       "393   0.844662  \n",
       "209   0.821227  \n",
       "109   0.792817  \n",
       "251   0.791750  \n",
       "698   0.774536  \n",
       "144   0.769984  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10] # these are false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dd8e8ed1-03c6-4069-b91d-9531e53cdb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "\n",
       "     pred_prob  \n",
       "233   0.042373  \n",
       "411   0.041573  \n",
       "244   0.040565  \n",
       "38    0.037162  \n",
       "23    0.030338  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wrong.tail() # these are false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8977d39e-33d4-4373-9223-f18e28fe44ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1.0, Prob: 0.914415180683136\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8564230799674988\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8540899753570557\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8447698354721069\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8446618914604187\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:5].itertuples():\n",
    "  _, text, target, pred, pred_prob = row\n",
    "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "30157ede-ea5c-4c1d-a137-a94e5fabfeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0.0, Prob: 0.04237303137779236\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.04157322645187378\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.040564775466918945\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.037161678075790405\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.03033807873725891\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false negatives (model predicted 0 when should've been 1)\n",
    "for row in most_wrong[-5:].itertuples():\n",
    "  _, text, target, pred, pred_prob = row\n",
    "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd99ed-3025-4a5f-9ea2-46b261b90006",
   "metadata": {},
   "source": [
    "### **Making predictions on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60dd1313-c46f-4351-a439-b386a82ee85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 0, Prob: 0.12716808915138245\n",
      "Text:\n",
      "New post: Cowboys believe Lance Dunbar&amp;#039;s ankle injury not serious http://t.co/XMCRedFXAt\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.05218258500099182\n",
      "Text:\n",
      "WHAT A DISASTER FOR SECRET  #TI5\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.08022814989089966\n",
      "Text:\n",
      "Ltd Toy Stamp &amp; Vintage Tonka TFD No 5 Pressed Steel Pumper Fire Truck  - Full read by eBay http://t.co/hTvyEnXCBS http://t.co/xSvPzxYRe3\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.05345901846885681\n",
      "Text:\n",
      "Don't let your #writing suffer a fatality! Learn how to seek and destroy bad writing--weekly on Live Write Thrive: http://t.co/VVuL9eGPe8\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.11754807829856873\n",
      "Text:\n",
      "@f_body95 never riding in the gaymaro ... Would damage my reputation\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.43238091468811035\n",
      "Text:\n",
      "#360WiseNews : China's Stock Market Crash: Are There Gems In The Rubble? http://t.co/QDwRjmmk89\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.9429948925971985\n",
      "Text:\n",
      "Rescuers are searching for hundreds of migrants in the Mediterranean after a boat carrying as many as 600 peopleÛ_\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.10141956806182861\n",
      "Text:\n",
      "Can't stand when ppl BeyoncÌ©'fy certain tunes nd u lot will b screaming 'yaaasss' low it I'm not tryna hear a xfactor rendition of burna boy\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 0, Prob: 0.046103447675704956\n",
      "Text:\n",
      "@local_arsonist @Cloudy_goldrush Man what ???? they be on some other shit\n",
      "\n",
      "-----\n",
      "\n",
      "Pred: 1, Prob: 0.9922482967376709\n",
      "Text:\n",
      "The 390-Year-Old Tree That Survived the Bombing of Hiroshima http://t.co/kEirA8MA3K\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset and visualizing them\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # our model expects a list as input\n",
    "  pred = tf.round(pred_prob)\n",
    "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{test_sample}\\n\")\n",
    "  print(\"-----\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
